### Desarrollado por
* Djedrielle Alexander
* Sebastian MuÃ±oz
* Isaac Gamboa
* Josue Salazar

## MÃ©tricas de los requerimientos no funcionales

### Performance

El equipo de desarrollo decidiÃ³ utilizar las siguientes tecnologÃ­as Python + Django + SQL Server.

1 request de pedir todos los registros a una base de datos SQLite desde una API con Django dura 75ms segÃºn los benchmarks realizados por Bednarz y MiÅ‚osz en [Benchmarking the performance of Python web frameworks](/Benchmarking_the_performance_of_Python_web_framewo.pdf).

Los benchmarks se llevaron a cabo en una mÃ¡quina con las siguientes especificaciones de hardware:

* CPU: Intel Core i7-8750H
* RAM: 16 GB DDR4
* Storage: 1 TB, Samsung SSD 970 EVO
* Operating System: Windows 10 Home 64-bit  

Â¿CuÃ¡ntas request por segundo es capaz de realizar una mÃ¡quina de estas segÃºn los benchmarks observados (asumiendo que solo tiene 1 worker)?

1/0.075 = 13,33 req/s

Â¿CuÃ¡ntas req/s ocupamos alcanzar segÃºn el requerimiento no funcional?

100,000/60 = 1667 req/s

Si 1 worker puede realizar 13,33 req/s, Â¿CuÃ¡ntos se necesitan para llegar a las 1667 req/s?

*SegÃºn la regla de 3* ~ 125

Utilizaremos 16 instancias de la mÃ¡quina `r7i.2xlarge` (cada una tiene 8 workers) esta nos permite cumplir con los requerimientos no funcionales relacionados a Performance y tambiÃ©n los relacionados a Scalability.

### Scalability

* REST + Django + SQL Server

* utilizando una mÃ¡quina Microsoft Windows con una CPU Intel Xeon E3-1230 (4 nÃºcleos fÃ­sicos, 8 hiperprocesos) y 24 GB de memoria, usando 4 CPUs se obtienen 691,66 req/s como lo podemos ver en el [benchmark](https://www.augmentedmind.de/2024/07/14/go-vs-python-performance-benchmark/#:~:text=This%20article%20benchmarks%20the%20performance,than%20for%20both%20Python%20frameworks)

* Transaccion: Ejecuta 200 solicitudes GET paralelas al backend REST durante un minuto.

* Requerimiento: 16,666 req/s (~1,000,000 req/min)

* Eligiendo la instancia "r7i.2xlarge" en AWS la cual posee 8 vCPUs, 4 CPU cores, si reservamos 10-15% se tiene que:

- Capacidad efectiva por pod usando 4 CPUs: 691.66 Ã— 0.85 â‰ˆ 588 req/s.
- Pods necesarios: 16,667 Ã· 588 â‰ˆ 29 pods.

- Como la capacidad de la instancia solo alcanza para 1 pod que usa 4 CPUs, entonces vamos a necesitar ~29 pods de "r7i.2xlarge" configurados en el archivo de k8s.

- Se utilizarÃ¡ Kubernetes (EKS) para contenerizaciÃ³n y autoescalado. Inicialmente se desplegarÃ¡n ~4 pods (cada pod 4 vCPU / 8 GiB, rendimiento de referencia ~691 req/s por benchmark), sobre nodos r7i.2xlarge (8 vCPU, 64 GiB). El autoescalado horizontal (HPA) se activarÃ¡ por CPU (70 %), memoria (70 %) y solicitudes concurrentes por pod (mÃ©trica http_requests_inflight vÃ­a Prometheus Adapter), pudiendo crecer hasta 30 rÃ©plicas (~x10) segÃºn demanda. [Archivo Config K8s](/deploy/k8s/base/promptSales-api.yaml)

### Reliability

Se va a usar el servicio [Amazon CloudWatch](https://aws.amazon.com/es/cloudwatch/?nc2=type_a) de AWS para el monitoreo de alertas del sistema.
CloudWatch se encargarÃ¡ de recolectar mÃ©tricas, logs y trazas, ademÃ¡s de activar [CloudWatch Alarms](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/AlarmThatSendsEmail.html) cuando se superen los umbrales definidos.

Las alertas crÃ­ticas se enviarÃ¡n mediante [Amazon SNS](https://aws.amazon.com/es/sns/), el cual notificarÃ¡ por SMS, correo electrÃ³nico y WhatsApp usando un webhook externo conectado al grupo de soporte tÃ©cnico.

Tasa de error permitidos 1% transacciones diarias.


### Availability

**Downtime permitido**:
A partir del requerimiento de disponibilidad mÃ­nima del 99.9 %, se calculÃ³ el tiempo mÃ¡ximo de inactividad permitido en un aÃ±o.
Un aÃ±o tiene 525 600 minutos, por lo que:

`525 600 x 0.999 = 525074.4 `

Al restar este resultado del total anual se obtiene el tiempo de inactividad permitido:
- 43.8 min mensuales
- 525.6 min anuales

**Balanceador de Carga**

Se va a usar el servicio [ALB](https://aws.amazon.com/es/elasticloadbalancing/application-load-balancer/) de AWS como balanceador de carga.
- Health checks: `interval: 10s`, `unhealthyThreshold: 3`, `timeout: 5s`.
- SLA AWS: [99.99%](https://d1.awsstatic.com/legal/AmazonElasticLoadBalancing/Amazon_Elastic_Load_Balancing_Service_Level_Agreement_2022-07-25_ES-ES.pdf)

**Kubernetes/EC2**

Se usa el servicio [EKS](https://docs.aws.amazon.com/es_es/eks/latest/userguide/what-is-eks.html) de AWS para kubernetes y [EC2](https://aws.amazon.com/es/ec2/) para computaciÃ³n.
- SLA EKS: [99.95%](https://d1.awsstatic.com/legal/amazon-eks-sla/Amazon%20EKS%20Service%20Level%20Agreement_Spanish_2022-05-04.pdf)
- SLA EC2: [99.99%](https://d1.awsstatic.com/legal/AmazonComputeServiceLevelAgreement/Amazon_Compute_Service_Level_Agreement_Spanish_2022-05-25.pdf)

**Bases de datos**

Para las bases de datos SQL Server se utilizarÃ¡ [Amazon Aurora](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_AuroraOverview.html)
- Aurora Multi-AZ (writer + reader)
- RPO objetivo: â‰ˆ 0 s
- RTO objetivo (failover): â‰¤ 60 s (conmutaciÃ³n automÃ¡tica a rÃ©plica).
- SLA: [99.99%](https://aws.amazon.com/es/rds/aurora/sla/)

Para MongoDB se va a usar [MongoDB Atlas](https://aws.amazon.com/es/partners/mongodb/)
- Atlas Replica Set (3 nodos, 2+ AZ)
- RPO objetivo: â‰ˆ 0 s
- RTO objetivo (election/failover): â‰ˆ 10â€“60 s.
- SLA: [99.995%](https://www.mongodb.com/legal/sla/cloud/atlas-database)

**Backups**

Se configurarÃ¡n backups automÃ¡ticos diarios en Amazon Aurora y MongoDB Atlas,
con una retenciÃ³n mÃ­nima de 30 dÃ­as segÃºn las polÃ­ticas de cada servicio administrado.

**Cache**

Para el cache se va a usar el servicio [Amazon ElastiCache for Redis](https://aws.amazon.com/es/documentation-overview/redis/) en Multi-AZ con Auto-Failover
- SLA: [99.99%](https://d1.awsstatic.com/legal/elasticache-sla/Amazon%20Elasticache%20Service%20Level%20Agreement_2023-11-27-es_la-R-C.pdf)

**Uptime**

La disponibilidad serÃ­a 99.905%, cumpliendo asÃ­ el requerimiento.

### Security

Se aplicarÃ¡ una autenticaciÃ³n basada en OpenID Connect. Esta serÃ¡ proporcionada por Okta.

Para cifrar los datos en la comunicaciÃ³n de REST se utilizarÃ¡ TLS. 

En las bases de datos Mongo y SQL Server utilizaremos el cifrado AES-256.

### Maintainability

El cÃ³digo se desarrollarÃ¡ de manera modular siguiendo DDD y separaciÃ³n de dominios.

Durante el desarrollo se seguirÃ¡ el siguiente GitFlow

El branch `main` se utilizarÃ¡ Ãºnicamente para llevar el control de versiones en producciÃ³n, estas son versiones finales de la plataforma. `develop` se utilizarÃ¡ para la integraciÃ³n de nuevas funcionalidades en preparaciÃ³n para la prÃ³xima versiÃ³n final.

TambiÃ©n se definen las siguientes sub-branches de soporte:

`feature/*` â†’ nuevas funcionalidades (creadas desde develop).

`release/*` â†’ preparaciÃ³n de una versiÃ³n antes del despliegue (desde develop, luego se fusiona en main y develop).

`hotfix/*` â†’ correcciones urgentes en producciÃ³n (creadas desde main y luego fusionadas de vuelta a develop).

Todo PR a `main` debe incluir una descripciÃ³n detallada del cambio que se realizÃ³. Se utilizarÃ¡n herramientas automÃ¡ticas (CI/CD) para verificar el formato, calidad del cÃ³digo y pruebas unitarias. Solo tras la aprobaciÃ³n de los revisores el cÃ³digo se integra a la rama principal.

Esta es la estrategia que se seguirÃ¡ para abordar hotfixes:

Primeramente se crearÃ¡ una rama desde main con el nombre `hotfix/*Info del bug*`, en esta rama se implementarÃ¡ y probarÃ¡ la correcciÃ³n, una vez esta estÃ© lista, se harÃ¡ un PR hacia main (para despliegue inmediato). Seguidamente se fusionarÃ¡ el hotfix tambiÃ©n hacia develop (para mantener sincronizadas las ramas). Por Ãºltimo se documentarÃ¡ el cambio.

Para el release de versiones se harÃ¡ uso de la rama `release/*version*`. En esta se harÃ¡n puebas QA para la validaciÃ³n funcional, de rendimiento y seguridad. En caso de que se necesiten correcciones menores estas se harÃ¡n sobre la misma rama. Luego se harÃ¡ un merge a `main` para desplegar en producciÃ³n, y a `develop` para sincronizaciÃ³n de cambios.

La estrategia de soporte post-release es la siguiente:

L0: Se crearÃ¡ y brindarÃ¡ soporte a centros de ayuda como foros y videos tutoriales. TambiÃ©n se dispondrÃ¡n chatbots con respuestas automÃ¡ticas y flujos guiados.
Todo esto se complementarÃ¡ con documentaciÃ³n tÃ©cnica y guÃ­as para desarrolladores.

L1: Se brindarÃ¡ soporte a solicitudes recibidas vÃ­a correo, chat o redes. TambiÃ©n se tendrÃ¡n a disposiciÃ³n scripts o flujos predefinidos para resolver problemas comunes.

L2: Para abordar los problemas no solucionados en L1 se dispondrÃ¡ de personal capacitado para brindar soporte al usuario hasta llegar a una soluciÃ³n temporal o definitiva. Este soporte serÃ¡ brindado a travÃ©s de reuniÃ³n virtual o presencial, dependiendo de la disponibilidad.

L3: En caso de no encontrar soluciÃ³n definitiva a un problema en L2, el usuario serÃ¡ referido a uno de los integrantes del equipo de desarrollo de la plataforma. Este integrante le brindarÃ¡ soporte al usuario y en caso de que darle soluciÃ³n implique realizar algÃºn cambio en la estructura de la aplicaciÃ³n, este proceso se llevarÃ¡ a cabo.

### Interoperability

En cuanto a la comunicaciÃ³n entre dominios, esta se reserva a que se haga Ãºnicamente mediante entes llamados Facades (fachadas).

Se agregÃ³ un dominio encargado de proporcionar integraciÃ³n a servicios externos a los demÃ¡s dominios. Este se llama
`Integration for Extern Services Domain`.

### Compliance

Todo pago o transferencia se hace con servicio de terceros. En nuestro PayPal serÃ¡ nuestro provedor.

A la hora de realizar las pruebas automÃ¡ticas de Owasp se aceptarÃ¡n un mÃ¡ximo de dos pruebas crÃ­ticas, siempre y cuÃ¡ndo ninguna de estas se encuentren en la lista de `OWASP Top 10 - 2021`. Se aceptarÃ¡ toda alerta leve relacionada a algÃºn elemente de UI.

### Extensibility

En futuras versiones el alcance de esta arquitectura se puede extender conectando REST APIs, creando nuevos MCP Servers o incluso acoplando nuevos dominios.

## Domain Driven Design

### PromptContent

**Dominios principales**

- Creative Briefing: Encargado de recopilar los objetivos, pÃºblicos meta, tono y lineamientos del cliente para generar el brief creativo que guÃ­a toda la producciÃ³n de contenido.

- Text Generation: Genera textos publicitarios, descripciones o copys basados en el brief aprobado. Aplica control de tono, idioma y longitud del mensaje segÃºn el canal.

- Image Generation: Produce imÃ¡genes, banners o ilustraciones usando modelos de IA y plantillas predefinidas, respetando los lineamientos del brief.

- Video Generation: Crea videos o animaciones a partir del contenido textual y visual generado. Gestiona duraciÃ³n, formato y metadatos por plataforma destino.

- Campaign Generation: Combina texto, imÃ¡genes y videos en piezas completas de campaÃ±a. Define variantes por canal, idioma y formato, y prepara entregables finales.

- Culture Campaign Generation: Adapta el contenido generado a contextos culturales e idiomÃ¡ticos, asegurando coherencia local y evitando sesgos o errores culturales.

- SEO & Adaptation: Optimiza el contenido generado para motores de bÃºsqueda y asistentes IA, ajustando keywords, tÃ­tulos y metadatos segÃºn mercado y canal.

- External Publishing: Gestiona la publicaciÃ³n del contenido en plataformas externas (redes sociales, CMS, blogs o herramientas publicitarias) y controla su trazabilidad.

- Cloud: Proporciona almacenamiento centralizado, versionado y recuperaciÃ³n de recursos multimedia, ademÃ¡s de controlar permisos de acceso entre dominios.

**Diagrama DDD PromptContent**

![DDD diagram](/diagrams/Promptcontent.png)

### PromptAds Domains

**Lista de dominios principales**

- Campaign Planning: Encargado de diseÃ±ar la campaÃ±a publicitaria a partir del objetivo definido por el cliente. Define los KPIs, canales, formatos y duraciÃ³n de la campaÃ±a.

- Targeting: Selecciona el pÃºblico objetivo al que se mostrarÃ¡ la campaÃ±a, segmentando por datos demogrÃ¡ficos, comportamiento, intereses y otras variables.

- Bidding and Budgeting: Establece las reglas de puja y presupuesto. Define cuÃ¡nto se invertirÃ¡ por canal o audiencia y cÃ³mo se distribuirÃ¡ la oferta en cada plataforma.

- Activation Manager: Se encarga de activar y publicar la campaÃ±a en las plataformas externas (Google Ads, Meta Ads, TikTok, etc.) utilizando listas de control de acceso (ACL) y herramientas de integraciÃ³n.

- Insights: Recopila y presenta mÃ©tricas clave de desempeÃ±o como clics, impresiones, CTR, tasa de conversiÃ³n y otros indicadores de efectividad en tiempo real.

- Attribution: Asigna crÃ©dito de conversiÃ³n a los distintos canales o interacciones que contribuyeron al cierre de una venta, permitiendo mejorar futuras campaÃ±as.

- Experimentation: Permite probar variaciones de campaÃ±as, audiencias o mensajes mediante pruebas A/B u otros mÃ©todos para optimizar resultados.

- Compliance: Supervisa el cumplimiento de regulaciones locales e internas. Aplica reglas por paÃ­s o cliente, impone lÃ­mites de gasto y registra cambios con trazabilidad (quiÃ©n, quÃ©, cuÃ¡ndo).

**Diagrama DDD PromptAds**

![DDD diagram](/diagrams/DiagramaDDDCorregido.drawio%20(1).png)

Se pueden observar la estructura de carpetas basada en este Domain Driven Design para PromptAds, asi como tambien plantillas de codigo de alguno elementos importantes como facades, contracts, use_cases y tests en la siguiente ruta -> [Organizacion y Plantillas](/PromptAds/)

Siempre que crees un nuevo dominio, agrega:

- `core/domain/<dominio>/...`
- `core/application/dto|interfaces|use_cases|facades`
- `core/infrastructure/db/models|repositories y adapters externos si aplica`
- `endpoints en api/v1/<dominio>/...`

### PromptCrm Domains
Este dominio se encarga principalmente del monitoreo de leads. Estos se registran y clasifican automÃ¡ticamente con sus respectivos datos de proveniencia. Para la interacciÃ³n con el usuario el dominio ofrece chatbots, voicebots y flujos automatizados de atenciÃ³n. Todo esto es proporcionado por la implementaciÃ³n de IA.

- Contacts Management Domain: registro de clientes, leads, cuentas, y organizaciones.

- Leads Segmentation Domain: clasificaciÃ³n por tipo, industria, potencial de compra, regiÃ³n, etc.

- Overall Leads Info Domain: consolidaciÃ³n de toda la informaciÃ³n e historial en una sola interfaz.

**Diagrama DDD PromptCrm**

![DDD diagram](/diagrams/promptCrmDDDdiagram.png)

### Business Domain (Global)
Este dominio se encarga de validar quÃ© funcionalidades de la plataforma el usuario es capaz de utilizar, esto va a depender del plan al que este se haya suscrito. TambiÃ©n se encarga de gestionar todo lo relacionado con pagos por parte del usuario.

**Diagrama DDD PromptSales**
![DDD diagram](/diagrams/promptSalesDDDdiagram.png)

### TecnologÃ­as
- Python: Lenguaje base del backend para todos los dominios.
- Django + DRF: Framework usado para exponer las REST APIs de cada dominio siguiendo DDD (viewsets, facades y clients).
- Aurora SQL Server
    - SQL Server: PromptCrm y datos de Global Domains (suscripciones, planes, billing).
- MongoDB Atlas: Base del dominio PromptContent para briefs, configuraciones y metadatos creativos.
- Redis (ElastiCache): Cache compartido para respuestas rÃ¡pidas, tokens temporales y soporte a rate limiting / eventos.
- EKS + EC2 r7i.2xlarge: ClÃºster donde corren los pods.
- Application Load Balancer (ALB): Balancea trÃ¡fico HTTPS hacia EKS y aplica health checks.
- CloudWatch + Alarms + SNS: Monitoreo centralizado y alertas automÃ¡ticas para cualquier dominio (logs, mÃ©tricas y notificaciones).
- Okta: Identity Provider externo para SSO y emisiÃ³n de tokens OIDC.
- TLS (ACM): Certificados administrados por AWS para cifrado HTTPS.
- Prometheus Adapter: Expone mÃ©tricas al HPA para autoescalado (CPU, memoria, requests en vuelo).
- GitHub + GitHub Actions: Control de versiones, CI/CD y despliegue automatizado al clÃºster EKS.
- Cognito: GestiÃ³n del acceso en el API Gateway valida tokens y pasa claims a los dominios sin acoplar la lÃ³gica de autenticaciÃ³n.
- Vercel: Plataforma de despliegue para el portal web.
### Versionamiento 
El versionamiento se hace a nivel de API y deployment, no solo de ramas.


Cada dominio expone endpoints versionados por ruta, por ejemplo:
- src/core/api/v1/brief/
  
Si se necesita una nueva versiÃ³n:

Se duplica la carpeta v1, crea v2, ahÃ­ modifica sin romper a nadie.
- src/core/api/v2/brief/

Cada versiÃ³n se despliega como un servicio independiente:

`promptcontent-api-v1`

`promptcontent-api-v2`

Se crea un nuevo deployment YAML: 
```yaml
metadata:
  name: promptcontent-api-v2
spec:
  containers:
    - image: promptsales/promptcontent:v2
```

El dev crea una nueva stage o base path mapping:

- /api/promptcontent/v1 - promptcontent-api-v1
- /api/promptcontent/v2 - promptcontent-api-v2

el gateway enruta el trÃ¡fico a la versiÃ³n correcta y ambas conviven.

GitFlow se usa solo para el ciclo de desarrollo (feature/, release/, hotfix/, main), pero la compatibilidad entre versiones se garantiza en la capa de API Gateway + EKS manteniendo deployments separados por versiÃ³n.


### Diagrama de arquitectura


## Big Pic
![DDD diagram](/diagrams/Captura%20de%20pantalla%202025-11-13%20235717.png)



## Otros Services relacionados al pub/sub model
![DDD diagram](/diagrams/Captura%20de%20pantalla%202025-11-13%20184323.png)

## Link a Miro 
https://miro.com/welcomeonboard/R1Z6NkY1clBwRHQ1allYbWRWMStuKyt4L3BGRFVyaFJ5WEd0aEdSdVhrdFkvZXAxR0REMExaODVLMlk4eHBJc0FzZWZFU3o3cUJGU0ppbGprdmNaeGNWSlE0U09TUnRlN0V4Wml6cmJzRnRnMUkyVmw2OHo2Vlc5SncrYldYd2p3VHhHVHd5UWtSM1BidUtUYmxycDRnPT0hdjE=?share_link_id=516617271561


## DiseÃ±o de base de datos
Se definieron los siguientes motores de base de datos:

- **PromptSales:** SQL Server
- **PromptCrm:** SQL Server
- **PromptAds:** SQL Server
- **PromptContent:** MongoDB

### Base de datos de PromptCrm 
![PromptCRM Database Diagram](/diagrams/PromptCrmDB.png)

Script de creacion: [PromptCRM](/DBCreationScripts/PromptCRM_CreationScript.sql)


### Base de datos de PromptContent 
![PromptCRM Database Diagram](/diagrams/promptcontentDB.png)

Script de creacion: [PromptContent](/DBCreationScripts/creacion-colecciones-promptcontent.py)

Ejemplos de documentos JSON:

- CampaÃ±as
``` json
{
  "campaignId": "CMP-VERANO-2025",
  "name": "CampaÃ±a Verano 2025",
  "description": "PromociÃ³n de productos refrescantes para temporada de verano.",
  "targetAudience": "JÃ³venes entre 18 y 30 aÃ±os en Costa Rica.",
  "campaignMessage": "Refrescate este verano con nuestra nueva lÃ­nea.",
  "contentVersions": [
    { "contentId": "CNT-001", "platform": "Instagram", "type": "imagen" },
    { "contentId": "CNT-002", "platform": "Facebook", "type": "video" }
  ],
  "usedImages": ["MED-IMG-101", "MED-IMG-102"],
  "status": "active",
  "startDate": "2025-01-05T00:00:00Z",
  "endDate": "2025-03-01T00:00:00Z",
  "createdAt": "2025-01-02T10:15:00Z",
  "updatedAt": "2025-01-10T14:30:00Z"
}

``` 

- Clientes
``` json
{
  "clientId": "CLI-001",
  "email": "contacto@tiendaeco.cr",
  "name": "Tienda Eco",
  "company": "Tienda Eco S.A.",
  "phone": "+506 7010-2020",
  "createdAt": "2024-12-15T12:30:00Z",
  "updatedAt": "2025-01-05T09:20:00Z",
  "status": "active",
  "subscriptions": [
    {
      "subscriptionId": "SUB-1001",
      "planId": "PLAN-EMPRENDE",
      "planName": "Plan Emprendedor",
      "status": "active",
      "startDate": "2025-01-01T00:00:00Z",
      "endDate": null,
      "renewalDate": "2025-02-01T00:00:00Z",
      "paymentStatus": "paid",
      "usageTracking": {
        "generacion_contenido": { "used": 35, "limit": 100, "resetDate": "2025-02-01T00:00:00Z" },
        "imagenes_ia": { "used": 10, "limit": 40, "resetDate": "2025-02-01T00:00:00Z" }
      }
    }
  ]
}

``` 

### DiseÃ±o de Data Pipeline
PromptSales usara un proceso ETL cada 15 minutos para mantener la informacion actualizada de las tres bases de datos, este data pipeline extrae datos de las bases de 
cada subempresa y la transfiere a PromptSales.

El servicio principal utilizado para orquestar la conexiÃ³n y el movimiento de datos es AWS Glue. Proporciona jobs de ETL en Python o Spark que permiten extraer, transformar y cargar informaciÃ³n desde las distintas fuentes hacia las tablas destino.

#### Criterios de Delta

Para extraer Ãºnicamente los registros nuevos o modificados, AWS Glue compara las columnas createdAt y updatedAt contra la marca de tiempo registrada en la Ãºltima ejecuciÃ³n del ETL. Si alguno de estos valores es mÃ¡s reciente, el registro se incluye en la carga hacia PromptSales.

En el diagrama se muestra este proceso:

![ETLPipeline Image](/diagrams/ETLDataPipeline.png)

## GuÃ­a de Desarrollo de MCP Servers

Esta secciÃ³n detalla los estÃ¡ndares y patrones arquitectÃ³nicos para la creaciÃ³n de nuevos servidores MCP en PromptSales.

### 1. Arquitectura en Capas
Todo servidor MCP debe seguir una arquitectura en capas para desacoplar la lÃ³gica de negocio de la definiciÃ³n de herramientas y el acceso a datos.

*   **`tools/`**: Definiciones de esquemas JSON para las herramientas (contratos).
*   **`handlers/`**: Controladores que mapean las peticiones MCP a la lÃ³gica de negocio.
*   **`service/`**: LÃ³gica de negocio pura. Orquesta llamadas a repositorios o APIs externas.
*   **`repo/`**: Acceso a datos (SQL, APIs externas). Maneja conexiones y reintentos.
*   **`index.ts`**: Punto de entrada. Configura el servidor y registra los handlers.

### 2. Pasos para Crear un Nuevo MCP Server

1.  **Definir Herramientas (`tools/definitions.ts`)**:
    Crear los esquemas de entrada usando TypeScript. Definir claramente `name`, `description` y `inputSchema`.

2.  **Implementar Capa de Datos (`repo/`)**:
    Crear funciones para acceder a la base de datos o servicios externos. Implementar lÃ³gica de reintento para conexiones (ver `initializeDatabase` en `repo/db.ts`).

3.  **Implementar LÃ³gica de Negocio (`service/`)**:
    Crear funciones que utilicen el repositorio para obtener datos y procesarlos segÃºn sea necesario.

4.  **Crear Handlers (`handlers/`)**:
    Implementar funciones `handleListTools` y `handleCallTool`. Usar un `switch` para despachar llamadas a los servicios correspondientes.

5.  **Registrar en el Servidor (`index.ts`)**:
    Inicializar el servidor MCP, conectar la base de datos y registrar los handlers para `ListToolsRequestSchema` y `CallToolRequestSchema`.

### 3. EstÃ¡ndares TÃ©cnicos

*   **TypeScript**: Uso obligatorio para tipado fuerte.
*   **Docker**: Cada servidor debe tener su propio `Dockerfile` optimizado (copiar solo lo necesario).
*   **Manejo de Errores**: Los handlers deben capturar excepciones y retornar respuestas de error formateadas, no dejar caer el servidor.
*   **ConexiÃ³n a BD**: Implementar reintentos (backoff) al iniciar la conexiÃ³n para tolerar tiempos de espera de la base de datos en el arranque.

## Prompts de Ejemplo

A continuaciÃ³n, ejemplos de cÃ³mo un usuario interactuarÃ­a con el agente y quÃ© herramienta se activarÃ­a internamente:

### Ejemplo 1: Rendimiento General
**Usuario**: "Â¿CÃ³mo le fue a la campaÃ±a xxxx el mes pasado?"
**Tool Call**:
```json
{
  "name": "get_campaign_performance",
  "arguments": {
    "campaignName": "xxxx",
    "startDate": "2025-10-01",
    "endDate": "2025-10-31"
  }
}
```

### Ejemplo 2: AnÃ¡lisis de Ventas
**Usuario**: "MuÃ©strame cuÃ¡nto dinero generÃ³ la campaÃ±a de xxxx."
**Tool Call**:
```json
{
  "name": "get_sales_data",
  "arguments": {
    "campaignName": "xxxx"
  }
}
```

### Ejemplo 3: DistribuciÃ³n GeogrÃ¡fica
**Usuario**: "Â¿En quÃ© ciudades estamos teniendo mÃ¡s impacto con la campaÃ±a xxxx?"
**Tool Call**:
```json
{
  "name": "get_campaign_locations",
  "arguments": {
    "campaignName": "xxxx",
    "granularity": "city"
  }
}
```

### Ejemplo 4: AuditorÃ­a de Canales
**Usuario**: "Â¿En quÃ© redes sociales se publicÃ³ el anuncio de la campaÃ±a xxxx?"
**Tool Call**:
```json
{
  "name": "get_campaign_channels",
  "arguments": {
    "campaignName": "xxxx"
  }
}
```

### Deployment

**Cloud**
El archivo [promptSales-api.yaml](deploy/k8s/base/promptSales-api.yaml) define el Deployment, Service y HPA usados por el cluster para ejecutar la API en producciÃ³n.

**CI/CD**
El workflow se encuentra en [.github/workflows/deploy.yaml](.github/workflows/deploy.yaml), y se ejecuta automÃ¡ticamente cuando se realiza un push a los branches main o deploy.

El pipeline instalado realiza tareas bÃ¡sicas de validaciÃ³n: instalaciÃ³n de dependencias, anÃ¡lisis estÃ¡tico y ejecuciÃ³n de pruebas. Esto asegura que cada commit pase por una verificaciÃ³n mÃ­nima antes de considerarse estable.
```yaml
name: PromptSales CI/CD

on:
  push:
    branches: [ "main", "deploy" ]

jobs:
  basic-ci:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v3

    - name: Set up Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'

    - name: Install Dependencies
      run: npm ci

    - name: Run Linter
      run: npm run lint

    - name: Run Unit Tests
      run: npm test

    - name: Basic Task
      run: echo "Pipeline ejecutado correctamente" > pipeline_output.txt

```
**Mantenimiento y Deploy de Migrations**

Para el mantenimiento y deploy de migrations en ambos motores (SQL Server y MongoDB) se va a utilizar [AWS DMS](https://docs.aws.amazon.com/es_es/dms/latest/userguide/Welcome.html).

Este servicio permite mover datos, aplicar cambios incrementales y ejecutar actualizaciones controladas entre ambientes sin afectar la operaciÃ³n.

---

## ğŸ§ª Testing & QA Suite

Esta secciÃ³n documenta la baterÃ­a de pruebas del proyecto PromptSales.

### ğŸ“‚ Estructura de Tests

```
tests/
â”œâ”€â”€ unit/       # Pruebas de lÃ³gica de negocio (LeadMetrics)
â”œâ”€â”€ api/        # Pruebas de integraciÃ³n REST API
â”œâ”€â”€ stress/     # Pruebas de carga distribuidas (Locust)
â””â”€â”€ mcp/        # Pruebas del servidor MCP (JSON-RPC)
```

### ğŸš€ Inicio RÃ¡pido

**Requisitos:**
```bash
pip install pytest requests locust ruff django
```

**Ejecutar todas las pruebas:**
```bash
python run_qa_suite.py --type all
```

### ğŸ“‹ Tipos de Pruebas

#### ğŸ—ï¸ Unit Testing
Pruebas de la clase `LeadMetrics`.
```bash
python run_qa_suite.py --type unit
```

#### ğŸŒ REST API Testing
Prueba endpoints `/api/health` y `/api/lead-metrics`. Requiere servidor Django activo.
```bash
python run_qa_suite.py --type api
```

#### ğŸ¤– MCP Server Testing
Prueba del servidor MCP via JSON-RPC. Requiere contenedores Docker activos (`docker-compose up -d`).
```bash
python run_qa_suite.py --type mcp
```

#### ï¿½ Security Testing
Valida permisos grant (acceso permitido) y deny (acceso denegado) en el endpoint `/api/admin/stats`.
```bash
python run_qa_suite.py --type security
```

**Tests incluidos:**
- âŒ Sin autenticaciÃ³n â†’ 401
- âŒ API key invÃ¡lida â†’ 403
- âŒ Permisos insuficientes (readonly) â†’ 403
- âœ… Admin vÃ¡lido â†’ 200 (access granted)
- âŒ Formato de auth invÃ¡lido â†’ 401

**API Keys de prueba:**
- Admin: `admin-key-12345` (permisos: read, write, delete)
- Readonly: `readonly-key-67890` (permisos: read)


#### ï¿½ğŸ› ï¸ Linter (Ruff)
```bash
python -m ruff check .        # Revisar
python -m ruff check --fix .  # Corregir automÃ¡ticamente
```

### ğŸ¦— Stress Testing Distribuido (Locust + Docker)

**Arquitectura:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Tu PC         â”‚
â”‚  (Master)       â”‚ â† Interfaz Web (localhost:8089)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”
â”‚Worker1â”‚ â”‚Worker2â”‚  â† Contenedores Docker
â””â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”€â”€â”˜
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Django API â”‚ â† localhost:8000
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Paso 1: Iniciar Master**
```bash
python -m locust -f tests/stress/locustfile.py --master
```

**Paso 2: Obtener tu IP local**
```powershell
ipconfig
```

**Paso 3: Crear Worker en Docker**
```bash
docker run --rm -v ${PWD}/tests/stress:/locust locustio/locust:latest -f /locust/locustfile.py --worker --master-host=<TU_IP>
```

**Paso 4: Abrir interfaz web**
http://localhost:8089

**Workers en otra computadora:**
```bash
docker run --rm -v /ruta/tests/stress:/locust locustio/locust:latest -f /locust/locustfile.py --worker --master-host=<IP_MASTER>
```

**Troubleshooting:**
- Workers no conectan: Verificar firewall (puerto 5557), usar IP correcta
- Django desde Docker: Usar `http://host.docker.internal:8000` (Windows/Mac)
